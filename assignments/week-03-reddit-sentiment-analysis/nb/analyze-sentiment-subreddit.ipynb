{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Reddit Data using Reddit API</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( ü§ó the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the end of each task, commit* the work into the repository you created before the assignment\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your repository you created before the assignment\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please ensure you've ran all the cells in the `imports.ipynb`, located [here](https://github.com/FourthBrain/MLE-8/blob/main/assignments/week-3-analyze-sentiment-subreddit/imports.ipynb), to make sure you have all the required packages for today's assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect uri** ( The redirect URI is where the user is sent after they've granted OAuth access to your application (more info [here](https://github.com/reddit-archive/reddit/wiki/OAuth2)) For our purpose, you can enter some random url, e.g., www.google.com; as shown below.\n",
    "\n",
    "\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jot down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    \n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets_reddit.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"client_id\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"secret_id\"\n",
    "    REDDIT_API_USER_AGENT = \"any string except bot; ex. My User Agent\"\n",
    "    ```\n",
    "- Add `secrets_reddit.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import secrets_reddit\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id = \"mD542C7kDIQfxqUA7EWABQ\",\n",
    "    client_secret = \"2Egznz-FXCarCqpgfj5-92PIsw_FtA\",\n",
    "    user_agent = \"testscript by u/Funny_Magician_1022\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get MachineLearning subreddit data\n",
    "ml_subreddit = reddit.subreddit('MachineLearning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected output you will see ar from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
      "--------\n",
      "+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
      "--------\n",
      "+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
      "--------\n",
      "+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
      "--------\n",
      "+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ANews)\n",
      "--------\n",
      "***[@slashML on Twitter](https://twitter.com/slashML)***\n",
      "--------\n",
      "***[Chat with us on Slack](https://join.slack.com/t/rml-talk/shared_invite/enQtNjkyMzI3NjA2NTY2LWY0ZmRjZjNhYjI5NzYwM2Y0YzZhZWNiODQ3ZGFjYmI2NTU3YjE1ZDU5MzM2ZTQ4ZGJmOTFmNWVkMzFiMzVhYjg)***\n",
      "--------\n",
      "**Beginners:**\n",
      "--------\n",
      "Please have a look at [our FAQ and Link-Collection](http://www.reddit.com/r/MachineLearning/wiki/index)\n",
      "\n",
      "[Metacademy](http://www.metacademy.org) is a great resource which compiles lesson plans on popular machine learning topics.\n",
      "\n",
      "For Beginner questions please try /r/LearnMachineLearning , /r/MLQuestions or http://stackoverflow.com/\n",
      "\n",
      "For career related questions, visit /r/cscareerquestions/\n",
      "\n",
      "--------\n",
      "\n",
      "[Advanced Courses (2016)](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses?st=isz2lqdk&sh=56c58cd6)\n",
      "\n",
      "[Advanced Courses (2020)](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/)\n",
      "\n",
      "--------\n",
      "**AMAs:**\n",
      "\n",
      "[Pluribus Poker AI Team 7/19/2019](https://www.reddit.com/r/MachineLearning/comments/ceece3/ama_we_are_noam_brown_and_tuomas_sandholm/)\n",
      "\n",
      "[DeepMind AlphaStar team (1/24//2019)](https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/)\n",
      "\n",
      "[Libratus Poker AI Team (12/18/2017)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/7jn12v/ama_we_are_noam_brown_and_professor_tuomas/)\n",
      "\n",
      "[DeepMind AlphaGo Team (10/19/2017)](https://www.reddit.com/r/MachineLearning/comments/76xjb5/ama_we_are_david_silver_and_julian_schrittwieser/)\n",
      "\n",
      "[Google Brain Team (9/17/2017)](https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/)\n",
      "\n",
      "[Google Brain Team (8/11/2016)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n",
      "\n",
      "[The MalariaSpot Team (2/6/2016)](https://www.reddit.com/r/MachineLearning/comments/4m7ci1/ama_the_malariaspot_team/)\n",
      "\n",
      "[OpenAI Research Team (1/9/2016)](http://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/)\n",
      "\n",
      "[Nando de Freitas (12/26/2015)](http://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/)\n",
      "\n",
      "[Andrew Ng and Adam Coates (4/15/2015)](http://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/)\n",
      "\n",
      "[J√ºrgen Schmidhuber (3/4/2015)](http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/)\n",
      "\n",
      "[Geoffrey Hinton (11/10/2014)]\n",
      "(http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)\n",
      "\n",
      "[Michael Jordan (9/10/2014)](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n",
      "\n",
      "[Yann LeCun (5/15/2014)](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/)\n",
      "\n",
      "[Yoshua Bengio (2/27/2014)](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/)\n",
      "\n",
      "--------\n",
      "Related Subreddit :\n",
      "\n",
      "* [LearnMachineLearning](http://www.reddit.com/r/LearnMachineLearning)\n",
      "\n",
      "* [Statistics](http://www.reddit.com/r/statistics)\n",
      "\n",
      "* [Computer Vision](http://www.reddit.com/r/computervision)\n",
      "\n",
      "* [Compressive Sensing](http://www.reddit.com/r/CompressiveSensing/)\n",
      "\n",
      "* [NLP] (http://www.reddit.com/r/LanguageTechnology)\n",
      "\n",
      "* [ML Questions] (http://www.reddit.com/r/MLQuestions)\n",
      "\n",
      "* /r/MLjobs and /r/BigDataJobs\n",
      "\n",
      "* /r/datacleaning\n",
      "\n",
      "* /r/DataScience\n",
      "\n",
      "* /r/scientificresearch\n",
      "\n",
      "* /r/artificial\n"
     ]
    }
   ],
   "source": [
    "# get MachineLearning subreddit data\n",
    "ml_subreddit = reddit.subreddit('MachineLearning')\n",
    "\n",
    "print(ml_subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 years ago today Rudy Giuliani held a press conference for Trump at Four Seasons Total Landscaping\n",
      "meirl\n",
      "‚ÄúGroomer‚Äù-obsessed Gov. Ron DeSantis partied with students as a 23-year-old teacher | Former students say the then 23-year-old attended parties with students where alcohol was served.\n",
      "He tried negotiating lol\n",
      "I joined the Air Force just before this was announced. My 4 year contract has already expired.\n"
     ]
    }
   ],
   "source": [
    "# get hottest posts from all subreddits\n",
    "hot_posts = reddit.subreddit('all').hot(limit=5)\n",
    "for post in hot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A San Antonio police officer shoots this 17 year old boy for what the officer believes to be a stolen car. The boy was eating a burger and causing no disturbance.\n",
      "Merry Christmas Amigazo!\n",
      "Are police allowed to make fun of you in an interrogation?\n",
      "Fun fact: Local police departments in Czech Republic has one or two \"police ambulances\", that are used to transport drunk people, or when the person needs to seek medical attention, but has to be supervised by police. Is this a thing in other countries like USA as well? NYPD has something similar.\n",
      "Lord protect our brave men and women in blueüôè‚úùÔ∏è Officer Gadson POV:\n"
     ]
    }
   ],
   "source": [
    "pl_subreddit = reddit.subreddit('police')\n",
    "#print(pl_subreddit.description)\n",
    "\n",
    "hot_posts = reddit.subreddit('police').hot(limit=5)\n",
    "for post in hot_posts:\n",
    "    print(post.title)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    machinelearning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Machine Learning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
      "--------\n",
      "+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
      "--------\n",
      "+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
      "--------\n",
      "+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
      "--------\n",
      "+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ANews)\n",
      "--------\n",
      "***[@slashML on Twitter](https://twitter.com/slashML)***\n",
      "--------\n",
      "***[Chat with us on Slack](https://join.slack.com/t/rml-talk/shared_invite/enQtNjkyMzI3NjA2NTY2LWY0ZmRjZjNhYjI5NzYwM2Y0YzZhZWNiODQ3ZGFjYmI2NTU3YjE1ZDU5MzM2ZTQ4ZGJmOTFmNWVkMzFiMzVhYjg)***\n",
      "--------\n",
      "**Beginners:**\n",
      "--------\n",
      "Please have a look at [our FAQ and Link-Collection](http://www.reddit.com/r/MachineLearning/wiki/index)\n",
      "\n",
      "[Metacademy](http://www.metacademy.org) is a great resource which compiles lesson plans on popular machine learning topics.\n",
      "\n",
      "For Beginner questions please try /r/LearnMachineLearning , /r/MLQuestions or http://stackoverflow.com/\n",
      "\n",
      "For career related questions, visit /r/cscareerquestions/\n",
      "\n",
      "--------\n",
      "\n",
      "[Advanced Courses (2016)](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses?st=isz2lqdk&sh=56c58cd6)\n",
      "\n",
      "[Advanced Courses (2020)](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/)\n",
      "\n",
      "--------\n",
      "**AMAs:**\n",
      "\n",
      "[Pluribus Poker AI Team 7/19/2019](https://www.reddit.com/r/MachineLearning/comments/ceece3/ama_we_are_noam_brown_and_tuomas_sandholm/)\n",
      "\n",
      "[DeepMind AlphaStar team (1/24//2019)](https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/)\n",
      "\n",
      "[Libratus Poker AI Team (12/18/2017)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/7jn12v/ama_we_are_noam_brown_and_professor_tuomas/)\n",
      "\n",
      "[DeepMind AlphaGo Team (10/19/2017)](https://www.reddit.com/r/MachineLearning/comments/76xjb5/ama_we_are_david_silver_and_julian_schrittwieser/)\n",
      "\n",
      "[Google Brain Team (9/17/2017)](https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/)\n",
      "\n",
      "[Google Brain Team (8/11/2016)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n",
      "\n",
      "[The MalariaSpot Team (2/6/2016)](https://www.reddit.com/r/MachineLearning/comments/4m7ci1/ama_the_malariaspot_team/)\n",
      "\n",
      "[OpenAI Research Team (1/9/2016)](http://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/)\n",
      "\n",
      "[Nando de Freitas (12/26/2015)](http://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/)\n",
      "\n",
      "[Andrew Ng and Adam Coates (4/15/2015)](http://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/)\n",
      "\n",
      "[J√ºrgen Schmidhuber (3/4/2015)](http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/)\n",
      "\n",
      "[Geoffrey Hinton (11/10/2014)]\n",
      "(http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)\n",
      "\n",
      "[Michael Jordan (9/10/2014)](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n",
      "\n",
      "[Yann LeCun (5/15/2014)](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/)\n",
      "\n",
      "[Yoshua Bengio (2/27/2014)](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/)\n",
      "\n",
      "--------\n",
      "Related Subreddit :\n",
      "\n",
      "* [LearnMachineLearning](http://www.reddit.com/r/LearnMachineLearning)\n",
      "\n",
      "* [Statistics](http://www.reddit.com/r/statistics)\n",
      "\n",
      "* [Computer Vision](http://www.reddit.com/r/computervision)\n",
      "\n",
      "* [Compressive Sensing](http://www.reddit.com/r/CompressiveSensing/)\n",
      "\n",
      "* [NLP] (http://www.reddit.com/r/LanguageTechnology)\n",
      "\n",
      "* [ML Questions] (http://www.reddit.com/r/MLQuestions)\n",
      "\n",
      "* /r/MLjobs and /r/BigDataJobs\n",
      "\n",
      "* /r/datacleaning\n",
      "\n",
      "* /r/DataScience\n",
      "\n",
      "* /r/scientificresearch\n",
      "\n",
      "* /r/artificial\n"
     ]
    }
   ],
   "source": [
    "# get MachineLearning subreddit data\n",
    "ml_subreddit = reddit.subreddit('MachineLearning')\n",
    "\n",
    "print(ml_subreddit.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[D] Simple Questions Thread\n",
      "[D] Machine Learning - WAYR (What Are You Reading) - Week 140\n",
      "[P] COCO captions translation to Nepali using Meta AI's NLLB model\n",
      "[D] Do you think there is a competitive future for smaller, locally trained/served models?\n",
      "[P] Transcribe any podcast episode in just 1 minute with optimized OpenAI/whisper\n",
      "[D] At what tasks are models better than humans given the same amount of data?\n",
      "[D] Medium Article: How to code Temporal Distribution Characterization (TDC) for time series?\n",
      "[P] Stable-diffusion's implementation of Paint-with-words : method from NVIDIA that generates images from text-labeled segmentation map.\n",
      "[D] Git Re-Basin Paper Accused of Misinformation\n",
      "[D] What's the best speech to speech deep fake voice project?\n"
     ]
    }
   ],
   "source": [
    "# get 10 top posts from the MachineLearning subreddit\n",
    "mlhot_posts = reddit.subreddit('MachineLearning').hot(limit=10)\n",
    "for post in mlhot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?ml_subreddit.top \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Postgame Thread] LSU Defeats Alabama 32-31 (OT)\n",
      "Investors hard at work.\n",
      "African painted dogs at the Oregon Zoo notice a visitor's service animal\n",
      "The longest elbow plank by a female (4 hours and 20 minutes!)\n",
      "Literally having her name repeatedly called over PA and holding up an entire flight for a cheeseburger\n",
      "He really does have tiny hands (I'm a 5 ft. tall woman for reference)\n",
      "[Charania] Sources: Nets have delivered Kyrie Irving six items he must complete to return to team: - Apologize/condemn movie - $500K donation to anti-hate causes - Sensitivity training - Antisemitic training - Meet with ADL, Jewish leaders - Meet with Joe Tsai to demonstrate understanding\n",
      "1665 london deaths\n",
      "meirl\n",
      "he's having a good day!\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE# get hottest posts from all subreddits\n",
    "allhot_posts = reddit.subreddit('all').hot(limit=10)\n",
    "for post in allhot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Chrome Extension to Fight Fake News\n",
      "What is artificial intelligence (AI)?\n",
      "AIA - ARTIFICIAL INTELLIGENCE ACT\n",
      "TPU killer?\n",
      "Guys!!! HELP What do you make of this???\n",
      "Why we are already invaded by robots and brainwashed..\n",
      "Apache Spark Consulting Company | Apache Spark Developers\n",
      "AI and language Intelligence: A Learning Companion For Employees\n",
      "10 crazy AI Tools Which Gonna Blow Up\n",
      "Artificial Intelligence And Blockchain: The Ideal Partners!\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "AIhot_posts = reddit.subreddit('ArtificalIntelligence').hot(limit=10)\n",
    "for post in AIhot_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple‚Äôs director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said ‚ÄúI believe strongly that more flexibility would have been the best policy for my team.‚Äù He was likely the company‚Äôs most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I‚Äôve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple‚Äôs version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "Check out what other attributes the `praw.models.Submission` class has in the [docs](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html). \n",
    "\n",
    "1. After having a chance to look through the docs, is there any other information that you might want to extract? How might this additional data help you?\n",
    "\n",
    "Write a sample piece of code below extracting three additional pieces of information from the submission below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give_me_the_truth\n",
      "seiqooq\n",
      "starstruckmon\n",
      "TiredOldCrow\n",
      "GroundbreakingArm944\n"
     ]
    }
   ],
   "source": [
    "for comment in reddit.subreddit(\"MachineLearning\").comments(limit=5):\n",
    "    print(comment.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "2. Is there any information available that might be a concern when it comes to Ethical Data? \n",
    "I don't see a fake avatar name being an issue, but perhaps other details could be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later üòä) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 453 ms, sys: 34 ms, total: 487 ms\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# YOUR COMMENT HERE: Initializing the list\n",
    "top_comments = []\n",
    "\n",
    "# For each of the elements in the top 10 comments\n",
    "for submission in ml_subreddit.top(limit=10):\n",
    "    # \n",
    "    for top_level_comment in submission.comments:\n",
    "        # Checking if the comment is of the same type (MoreComments) then ignore else append to list\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # \n",
    "        top_comments.append(top_level_comment.body)\n",
    "#print(top_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746\n",
      "['Simple yet very useful. Thank you for sharing the code.', 'The future ü§Ø', 'Ohh the nightmare of making this into a stable product... Enough to drive you mad just thinking about it', 'Almost guaranteed, Apple will copy your idea in 3, 2, 1....', 'Wtffff. Well that was incredible.', 'Apple can‚Äôt wait to steal this and not credit the creators', 'fantastic!', 'Why did the boxes in the diagram turn gray?', 'How does the Algorithm decide what it cuts out from the input pictures? \\n\\nFor example it only cut out the two people in the picture and not the surroundings.\\n\\nAmazing project though!', '#WITCH!  BURN THEM!', 'This will be amazing if released, even as a beta. Definitely can see this being very useful', 'Any sufficiently advanced technology is indistinguishable from magic.', 'Really good work, thanks for sharing!', \"I'm extremely impressed with it cutting dark hair from a brown background. Is that the pixel's camera doing the hard work or is it U^2_Net ? Have you tried it with other phones? How does it deal with feathering? Stunning demo & thanks for posting this.\"]\n"
     ]
    }
   ],
   "source": [
    "#YOUR CODE HERE  # the answer may vary 693 for r/machinelearning\n",
    "print(len(top_comments))\n",
    "print(top_comments[1:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why tf is this visually satisfying',\n",
       " 'What about tablets and computers?',\n",
       " 'This feels scary but I would love to give all my old pictures a spin.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "3. After having a chance to review a few samples of 5 comments from the subreddit, what can you say about the data? \n",
    "\n",
    "HINT: Think about the \"cleanliness\" of the data, the content of the data, think about what you're trying to do - how does this data line up with your goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ho lee fuk \\n\\nyou got anymore insider information? üëÄüëÄ', \"What will happen if you post that GME it's the new buy target from them? ü§£\", 'When are you all buying $DOGE, and how much will you all buy?', 'Papa Musk?? üòòüòòüòò', 'I really don‚Äôt understand what Musk is trying to do. It seems he is trying to legitimize BTC and create a sustainable ecosystem for it. But I question whether Tesla shareholders are going to be happy with such an unplanned use of invested capital. Musk is not the majority of Tesla, and big shareholders are very very picky about where their portion of $1.5bm goes to!', \"lmk when they start loading up on Doge and I'm in\", '[deleted]', 'When is DOGE flying', 'Are they gonna fire you lol', \"You're a fucking legend\", 'Give this man a raise! (In BTC)', 'Do you have twitter or instagram?', \"Could you point me in the right direction on to how to code one of this bots myself. I'm a developer and have an extensive trade background. I've been interested in trading algos for a while, but have no idea where is the best place to start learning\", 'Elon....come on.....we got ya...right?', 'BEEEEET-CO-NNNNNNNNNNEEEEEEEEEEEEEEEECT', 'Are you legally allowed to share that information though before they announced it?', 'trust the process', 'Let‚Äôs see if this investment has any effect on the actual stock. Good or bad.', 'Some of us only read, rarely post.', 'Have you ever talked with Elon? Could say few words about him? Thanks', 'You did - nicely done !!!', 'What will trigger the sell bot? How much % down swing?', 'WOW DUDE YOUR AWSOME !!', 'Which other Crypto do Tesla plan to approve?', 'I followed.', 'I followed you, maybe next time', 'This guy!!', 'When $ETH?', 'This was def just a prediction. Not an insider. He keep Rick rolling people -_____-', 'Good one @TSLAinsider üëç\\n*thefeelsofbeeingright ü§©', 'Sup', 'Elon?', 'You sure did. Great heads up. Your awesome!!!', 'Shiiiiit', 'Or you are actually an insider and freaked out that the post got attention lol. \\n\\nPm me with the next hot tip lol', 'Best advice I can possibly give just keep taking LSD if you are having those types of epiphanies LOL', 'Enjoy getting fired.', 'Lies...why would an R&D person in the company be involved in this? I don‚Äôt buy it.', '[removed]', \"Well since TSLA's last split was 5 to 1 at around $2,500, and since Elon said he doesn't want  split any time soon, I don't think it will happen, even though a lot of people want it to happen.\", 'I think you mean 5 for 1', \"I'd like to sell my one tesla share for 10 million. Thanks\", \"Would be great but Elon said he wasn't in a hurry to do that again\", 'I‚Äôm holding 34 shares at $418 average. Will I be able to average down once the stock splits?', 'I‚Äôm here for the split üòé', 'It would make sense to do a split soon so that more people can buy into it. I hope Elon splits it before the end of the year', 'You are confused!!!!!!', 'I can see a split after Elon sells his 10% as an announcement would drive up the price.', 'Yes Yes Yes', 'Definitely would like.', 'Tbh it‚Äôs only a matter of time', 'Thing is he only earns 10% of Tesla so if it‚Äôs a majority vote he has no choice but to split', 'Here is a very interesting theory/conspiracy https://twitter.com/robgrav3s/status/1461111661310398469?s=10', 'Send a tweet to papa Musk', 'It‚Äôs gonna happen 10000000000000% on December 9th exactly', '[removed]', 'Karma would eventually catch up with TSLA making a shitty product which is overpriced and all the false claims about autopilot and putting people‚Äôs lives in danger', 'Tesla will half its price by year end no need to split', 'Holding shares, happy with position, and wait for another 5:1 split. Smells like money and taste like chicken.  Let‚Äôs see what happens. For me I can buy TSLA car and drive a Honda HRV.  Why show your money, when you can buy more stonks. Upvote for others to read. This is the way and so say we all.', 'Me too. I am all dipped out. 400 shares long on Tesla. Made plenty of money bought and sold. Waiting for another split. Let‚Äôs run this to 10,000', '[removed]', 'üôÑ Literally me and TSLA right before this biiiiig \"correction\"', 'Hehehehe I am long on Tesla. It is better than FAANG except aapl.', \"So funny! Same thing can't buy anymore dips\", 'I feel the pain... I‚Äôm embarrassed if people look at my screen and see today‚Äôs expiration value üò¢', ' Q4 sales at average 50k per vehicle would mean 9B sales or 36B on yearly basis (very optimistic), margin 12% (very high) would mean 4$ per share, real profit is 0,59, get it?', 'FACTS SIR!!!üòíüòåüòîüò™', 'One of these days also TSLA will have to show profits in line with its stock prize, that defines the ultimate dip target, we are way too high right now', 'People need to stop talking about a stock split. It‚Äôs not productive. With the ability to buy fractional shares from most brokerages, it isn‚Äôt needed. \\n\\nRealistically, the share price should be in the $800 range, and should have been coming out of earnings. The run to the $1200s was a gamma squeeze triggered by that Hertz announcement. No technical support for it. Where we are now is not a dip. It‚Äôs the unwinding of shares purchased to hedge that‚Äôs pushing it down. When we get back to $800s, expected. If we get to $700s, dip and incredible buying opportunity. Sustained growth requires some pullback, support, resistance, and testing both. Elon selling stock is a distraction. He owns ~20% of Tesla. Selling 10% of that is 2%, which gets swallowed up by regular trading volume. Keep buying, be patient, we‚Äôll eventually get back over $1200 with proper support. Might take a few years.', 'TSLA is a promising stock, as long as it keeps on promising.', 'MUSK sells promises (memes) primarily, and products, secondarily.  TSLA sells EVs but what does SpaceX, Boring Co., Neuralink, Skylink, etc sell?  Promises, but not even that, just ideas of uncertain utility and unclear profitability.  He even jumped into crypto with Dogecoin.   One of these ideas or memes may prove profitable, but highly unlikely for the retail investor to win with any one memes of his.  TSLA is an interesting idea, but not practical for long range driving, especially when factoring in the safety issue of evacuating from foci of natural or man made disasters.', '60 shares @ $40.32 cps holding strong!', \"Can't say I'm super OG, but I've been following the company since 2016ish when I was a freshman in high school, and as soon as I got a bank account in 2020 I bought 1 share. I've been adding more since, without selling, and now I'm up to 8.5 shares at an average cost of 583.\", 'I just buy more', '75 Shares baby \\n\\n90% of my portfolio', 'Never sell! OG', 'Still holding 20 shares . I‚Äôm kinda poor', 'This stock will be worth 20 fold in 10 years time the way it‚Äôs going', 'Holy shit! I went from up +32k to down 3k to back up 20k! Never sold, just kept adding on the way down!', 'üñêÔ∏ènot touching my TSLA for the next 4-5 years at least.', \"Jumped in for the first time at $805. I'm a happy camper :)\", 'Nope I wussed out with the economy and Russia. And to top it off I bought a lot near the peak- $1052 and sold it off well under that. \\n\\nFortunately I lost $50 only. I bought/sold more as it made its descent into hell and back. \\n\\nUnfortunately I should have held when it was at below $800. \\n\\nI‚Äôll buy it. But not at $1000.  I simply cannot imagine this going to $2000 with all that‚Äôs going outside of Tesla‚Äôs control. \\n\\nI‚Äôll look at $900, maybe dip in at $800 and love it at $700.', 'I Really Don‚Äôt understand what to write Trying to help.', '55@340. Why would I leave?  I just need to get better at adding more.', \"Holding 415 shares since 450 (presplit)\\nI'm gonna hold for another 5-10 years.\\n\\n\\nIf Tsla eventually overpasses Apple as the most valuable company ill become a Teslionaire!!\", 'üôå I have never sold a share since 2017, and keep dollar cost averaging in.', \"didn't sell shares today\\n\\nauto executed 2 trailing stop loss options with 87% profit. fuck yeah!\", '820 shares and 4 longterm puts sold for about 100k premium (strike between 600 and 900)\\nbought first share in Dec 2018 and only added until then. hope I can retire in 5 years üòÜ', '10 from 500 days. Bought one more during 800 low last week. Wishing my tax return would come in before giga Austin opens up!', 'I NEVER SOLD MY CHAIRS !!!!!\\n\\nEVEN IF MY SELL LIMIT\\nORDER OF 1,200 hits \\n\\nI‚Äôll be there to catch Tesla at any falling knife event \\n\\nMe and Tesla have the world to\\nSave \\n\\n#AVENGERS ASSMEBLE\\nTESLA COCCK', \"I stayed long.\\n\\nNot because of faith.\\n\\nBecause of Tesla's increasing dominance and profit.\", 'When‚Äôs this stock split happening ?', 'Stacked up on Tesla and big oil 2 years ago. Can‚Äôt be happier.', '15 \\n\\nDoesn‚Äôt matter what the market does \\n\\nThese 15 aren‚Äôt going anywhere', 'How high is it projected to go? Just found out I have quite a few shares still from when I bought years ago. Sold a few of them back then and somehow forgot I had others!', 'Maybe we‚Äôre all a little crazy‚Ä¶but I‚Äôm holding and hoping that it‚Äôs a great call today. It will be brutal if there are surprises in Q1 or forecast. Hopefully Shanghai won‚Äôt be a reason for continued selling. Investors are in a bear mood over NFLX!', 'I consolidated my losing options to one new option and made some good money on it so far but not enough to cover the losses. :/ still have my stock though.', 'Over valued stock right now. Will definitely buy back when it hits 100-300 bucks.', 'Every Friday.', 'Buy one on first day of the month.', 'Sucks to be poor üò≠', 'Me for the past two years', 'Buy the dips, because Musk needs your money to pay his taxes.', 'Tesla is a steal at the current price. Buy the stock and see$1000 by the end of August.', 'I bought back when it was bouncing around $300s pre split. Then it went up to $800 + pre split down back to $300s. I was too scared to buy more but finally did around $490 pre split. When everyone asked if I sold I said I bought more. And here we are... this past couple of weeks have been painful but I do believe in TSLA long term. It‚Äôs going to be hard stomaching any more ‚Äúdips‚Äù but I‚Äôm trying to stay in perspective. It‚Äôs really hard trying to see big picture sometimes. Ugh. Hang on everyone!\\n  \\n\\nAverage cost per share $49 (bought before split)', 'I‚Äôm not gunna lie I haven‚Äôt been investing for long and have been testing the waters but when I seen TSLA so cheap i bought a full share, I realise this isn‚Äôt a lot to some people but it is to me haha, Gunna hold this bad boy indefinitely', 'Buying more is my strategy. \\n\\nI sold mine to lock in profit from 2015 and been waiting for this moment. (I was so worry that I will never get the stocks again lol...now I‚Äôm happy.) I keep buying 10 more on each down day starting from $785.', '[deleted]', 'I saw a Tesla go from $173 to $1500. Elon musk is a beast. He‚Äôs always fighting off the short sellers and still on top. It‚Äôs like all the Rocky movies doesn‚Äôt matter how many times you hit him he just keeps coming back until you‚Äôre too weak to fight back and then Bam a legend is made. Don‚Äôt take my word for it do you‚Äôre own  research. If I had a nickel for every time I heard someone say I wish I would‚Äôve bought it when it was low....', 'What do you think make the shorts choose TSLA?\\n\\nYour refusal to see reality is music to their ears, they sell more at your expense. The index players know this but it takes time for them to get out.', 'Title sounds delusional ...', 'There wasn‚Äôt really any bad news for Tesla, everything looks great so far. The old boys club is just trying to weed out the retail.', 'Tesla share is at 40% discount right now. Buy it or leave it.', 'Diamond hands üôå hold to the fucking moon. I‚Äôm gonna smoke a bowl and eat crayons', 'Cathie Woods is prepping a new price target. Should alleviate some FUD', \"$580 and falling today. What's your price target?\", 'Partially agree. It will reach $2000 in 2025. \\n\\nI had around the same 12K in 2017- took some profit in late Jan. Came back again at $530 today. You need some profit taking as well its good for everybody', 'The Great Short of TSLA is not Burry, but MUSK!', 'My 10k became 6k', \"Oh for the love of all that's holy.\\n\\nTSLA is falling for the same reason many other tech and growth stocks are falling. Money is simply being diversified into recovery stocks, because the real economy (remember that?) is recovering. Interest rates may rise, so yields may rise too, and so the smart money is moving into more traditional companies. It's a cycle, it always happens, and if you're investing and don't know this simple stuff, well then good luck with your strategy.\\n\\nNo one is saying Tesla is in trouble or going to fail or not still an incredible company and worth buying, but it's just there are other stocks now worth buying and stock prices are relative to one another.\\n\\nIf you believe and don't need the money, hold. If you were in it for a quick fix, you might get hurt.\", 'That stupidity of Bitcoin buying spooked a lot of investors. Now Musk tied his and every investors ass to BTC. It was a Bad Move to go out buying Criptos and blowing dog whistles at an idiotic asset like Dogecoin. That conveys non sereousness on part of Musk. On Wall Street Perception is Everything. Now we are Bleeding.', 'Interesting, looks like this sub is still bullish!', 'I bot 1 share today u/596', 'Meh come back to fight another day', 'üòÇüòÇüòÇ hold it! Be a macho and hold till the end üòÇüòÇüòÇ', \"Got it at @400.00 and see it to $901.00 until now, I won't sale for ever!\", 'Take profit before it turns to Coal', 'Dont splits normally happen in July time frame?', 'I like how it is right now, where the price is very similar to the market cap in billions.', 'I can‚Äôt wait for a stock split.', 'That‚Äôs not how it works but good luck. Stocks don‚Äôt split normally near that close to a previous split. There hasn‚Äôt even been a decent correction since the last split. I wouldn‚Äôt expect one for years', 'Anyone holding calls for November 26? Are you guys selling it this week due to FOMC or riding it until your expiration date?', 'If it ever splits again there will be some people panic selling. This will be a great opportunity to buy TSLA if the 2nd split happens this year or later', 'What does a split mean? Is it bad for people that have shares?', \"I'm sure they will do it but only because we all know what it will do to the stock.  ;)\", \"Isn't it solely up to Elon?\", \"He said he didn't wanna split. They won't split anytime soon unless tesla magically holds 2k a share value. It'll probably sit between. I'm bullish but what would tesla market cap be at 2000$ a share?\", 'Sorry to those that are about to miss the boat', 'Cathie Wood is a superstar', 'TSLA $2,500+ HODL!', 'These memes get wilder every day', '\"All Hail the Queen!\"', 'Second leg down coming. She better grab a life raft and drop the rod. Chopping wood!!', '**Fell of the chair.. Awesomely put together**', \"I truely think this is probably the last opportunity to buy tesla at a reasonable price.\\nCome 2022 and TESLA is going to fire on all cylinders, model 3 in full speed, cybertruck, 18 wheeler and a possible announcement of commercial electric airplane.\\nTSLA is going to do to cars what Apple did to phones; power of an ecosystem can't be underestimated.\", 'What do you guys think of EV competition from tradition automakers? Can traditional auto makers like GM catch up in terms of EV market share in near future/ ever?', \"\\nRight now, it's actually a great opportunity to buy TSLA at such a huge discount. When it's back over 800, we'll already have locked in a 35% gain! üòéüëç\", 'I think I like the stock', 'We need another WSB short squeeze to fry those shorts.', 'TSLA shorts will never learn', \"There are three things that will serve as an outpost for Tesla's stock price... 1: Market strategy (if Tesla still uses FSD to make money from customers) I will choose to sell out Tesla's stock.. 2  : Price strategy (if Tesla can‚Äôt offer consumers an irresistible preferential price because it reduces the components by two-thirds of the cost of a gasoline car) I will choose to sell out Tesla‚Äôs stock.. 3: Energy strategy: (if  Tesla cannot provide consumers with free charging at super charging stations for 5 years) I will choose to sell out Tesla‚Äôs stock\", 'Not selling a single share is like saying I‚Äôm never folding Texas hold ‚Äòem maybe you‚Äôll win some but you‚Äôd make more money if you folded sometimes and then came back', 'Base in uk, who knows best apps to buy and sell or FOR investors for TSLA.....Thank you guys!', 'It‚Äôs going to drop to 400s first. Buy up around there, and continue to buy puts', 'So many bots in here', 'When‚Äôs the right time to buy though? Will it drop more before going back up?? What‚Äôs peoples expectations', 'yeah it probably bounces a bit on its way to $300 EoY', '[deleted]', 'Hold then.\\nNever sell.', 'I just commented something like this. \\nI‚Äôm tapped. Need more money lol. \\nThis dip is so juicy....', 'You have balls of steel my friend! I‚Äôm hodling 75 and hoping to buy more next week.', 'This is the way.', 'Keep it up champ..Let that dick swwaaannggüìà', \"Just maybe it's happening now, adjusting value to expected earnings in an ever more competitive market\", 'Get a job, Sir!', 'sorry OP I bought in last week and now it must go down', 'What cost basis though OP?', 'How come we are all out of money?', \"Holing 300 at $870. It fucking hurts and kick myself for throwing that much at ATH's. Thankfully I don't need to liquidate any of it so I can ride it out\", 'I laughed heartily :)\\n\\nI sold some of my shares at loss and bought $590 call options. I hope it is near the bottom. Otherwise, I am screwed too.']\n"
     ]
    }
   ],
   "source": [
    "from praw.models import MoreComments\n",
    "tsla_reddit = reddit.subreddit('TSLA')\n",
    "\n",
    "top_comments_tsla = []\n",
    "\n",
    "for submission in tsla_reddit.top(limit=10):\n",
    "    for top_level_comment in submission.comments:\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        top_comments_tsla.append(top_level_comment.body)\n",
    "print(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What will happen if you post that GME it's the new buy target from them? ü§£\",\n",
       " 'trust the process',\n",
       " 'Karma would eventually catch up with TSLA making a shitty product which is overpriced and all the false claims about autopilot and putting people‚Äôs lives in danger']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I‚Äôm bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "4. Now that you've had a chance to review another subreddits comments, do you see any differences in the kinds of comments either subreddit has - and how might this relate to bias? \n",
    "\n",
    "Answer: From the above comments, it seems to me that folks who comment on the reddit social media have strong opinions, which may or may not be factual or honest or true. It's more a platform to vent extreme emotions, cursing and swearing, as well as genuine thoughts. But the majority of the opinions seem to be NOT moderated. So yes, it seems to me that the comments on reddit and possibly biased towards the extreme views of folks who follow Tesla. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8886483907699585}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "sentiment_model(\"top_comments_tsla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment = random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I‚Äôm holding 34 shares at $418 average. Will I be able to average down once the stock splits?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiment = sentiment_model(\"I‚Äôm holding 34 shares at $418 average. Will I be able to average down once the stock splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "Label and score. Dict.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: I‚Äôm holding 34 shares at $418 average. Will I be able to average down once the stock splits?\n",
      "Predicted Label is NEGATIVE and the score is 0.998\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üñ•Ô∏è‚ùì Model Question:\n",
    "\n",
    "1. What does the score represent? \n",
    "\n",
    "Answer: Score represents that the sentiment expressed in this comment is overall negative. In all honesty, the comment would make sense to someone with finance background. To me, it is hard to tell what the comment means - perhaps that the person is concerned about losing money? So my reading is neutral. I am not sure I can judge what this means without asking a finance person about the comment. But the reason the sentiment came out as negative is because of the 'average down' part? Not sure, but it is very interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_tlsa_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tlsa_comment_sentiment.py\n",
    "\n",
    "import secrets_reddit\n",
    "import random\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def get_subreddit(display_name:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"\n",
    "    reddit = Reddit(\n",
    "        client_id=secrets_reddit.REDDIT_API_CLIENT_ID,        \n",
    "        client_secret=secrets_reddit.REDDIT_API_CLIENT_SECRET,\n",
    "        user_agent=secrets_reddit.REDDIT_API_USER_AGENT\n",
    "        )\n",
    "    \n",
    "    subreddit = reddit.subreddit(display_name)\n",
    "    return subreddit\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, MoreComments):\n",
    "                continue\n",
    "            top_comments.append(top_level_comment.body)\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    subreddit = get_subreddit('TSLA')\n",
    "    comments = get_comments(subreddit)\n",
    "    comment = random.choice(comments)\n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "The comment: Would be great but Elon said he wasn't in a hurry to do that again\n",
      "Predicted Label is NEGATIVE and the score is 0.982\n"
     ]
    }
   ],
   "source": [
    "!python top_tlsa_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "5. Is the subreddit active? About how many posts or threads per day? How could you find this information? \n",
    "\n",
    "Answer: Seems like 2.5 million people are active on this subreddit. Ran out of time to find out how many posts per day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "6. Does there seem to be a large distribution of posters or a smaller concentration of posters who are very active? What kind of impact might this have on the data? \n",
    "\n",
    "Answer: Smaller number are active. Only 400 are active out of 2.5 million. Impact on the data - when we read from reddit, we are oversampling this small crowd as opposed to the real population and the smaller group is not a good representation of the larger group, which implies it's strongly biased by those who self-select to engage in the conversation and what we see reflects the view of the few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "c57794392b841cffd8686d5c4548e4e2ec78521f49300d60954d1380f1b4bd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
